{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3gscWN3GRtc"
   },
   "source": [
    "# Basic Data Handling\n",
    "\n",
    "This lab will cover the basics of Pandas, NumPy and Jax, and how they can be used to load data into PyTorch to train models. \n",
    "\n",
    "While teaching Scientific Python is outside the scope of the course, being able to load and preprocess data is an essential aspect of trianing and deploying deep learning models.\n",
    "\n",
    "There are plenty of resources online that cover this topic in much more detail such as:\n",
    "\n",
    "https://github.com/guiwitz/NumpyPandas_course\n",
    "https://docs.jax.dev/en/latest/notebooks/thinking_in_jax.html\n",
    "\n",
    "If you are unfamiliar with these pacakges, it is very much worth your while spending time getting to grips with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsQsg1LHGYhS"
   },
   "source": [
    "## NumPy (https://numpy.org/)\n",
    "\n",
    "Described as 'the fundamental package for scientific computing with python'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yxb1PMDHKJj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2_AAcCfIEts"
   },
   "source": [
    "The main purpose of NumPy is to allow us to perform mathematical operations easily and efficiently over multi-dimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3wbkTS0ImzT"
   },
   "source": [
    "### Python Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1WwO887ItXG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_list = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCerVUdaI6J_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(simple_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPejIHwiI_AK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(simple_list[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0i-NrCwFJIX5"
   },
   "outputs": [],
   "source": [
    "###### EXERCISE ######\n",
    "# create a new list from simple_list, with values double that of simple_list\n",
    "new_list = []\n",
    "\n",
    "# .. your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMF0JBOoIyf2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_2d_list = [[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXdKXF_-JBZs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(simple_2d_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z91J17IPJEtx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(simple_2d_list[0][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ojtctQsJYJt"
   },
   "outputs": [],
   "source": [
    "###### EXERCISE ######\n",
    "# Is it possible to slice the 2D list, to get the first 3 elements of the first 2#\n",
    "# rows in a new 2D list?\n",
    "\n",
    "small_slice = # ... your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Tu_vPnHHQ72"
   },
   "source": [
    "### Creating NumPy Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JNIKWdVJ0fm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list = np.array(simple_list)\n",
    "np_1d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDxbgTJVKKNq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list = np.array(simple_2d_list)\n",
    "np_2d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5KdRhgbMDzC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXmkWQdVMBDa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvLh8MBsUpvA"
   },
   "source": [
    "When creating NumPy arrrays, it is also possible to declare the data type (dtype) that they will contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5layujxUx8t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list = np.array(simple_list, dtype=np.float32)\n",
    "np_1d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9B_s7DdVK2e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list = np.array(simple_list, dtype=np.complex128)\n",
    "np_1d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0LEC3AhVmR1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list = np.array(simple_list, dtype=str)\n",
    "np_1d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvmH_1a6VHte",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list = np.array(simple_list, dtype=np.int16)\n",
    "np_1d_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtLrj_6eKhDF"
   },
   "source": [
    "### Indexing and Slicing\n",
    "\n",
    "Selecting or indexing elements from NumPy arrays is similar to doing so with standard Python lists, but with much more flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUuAgEbtKjdq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtmlSQxAKmDi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiU43aekKnsQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gb_fUyu0Kali",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list[0:2,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtOjocpAV6R3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "elements_selected = np.array([True,False,False,True,True])\n",
    "np_1d_list[elements_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFm8k8uUKP1u"
   },
   "source": [
    "### Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D69q-Cf0KvZ6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qH9NIum7K1cn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34UPsoU1K3Cy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.exp(np_1d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KYpQXbvK5b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.max(np_1d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Us1oTjITK7dp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_np_1d_list = np.array([10,20,30,40,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPHjkTKTLCxT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list+second_np_1d_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpKPos89LQC3"
   },
   "source": [
    "\n",
    "These same operations work with higher dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnwTi0sILVyy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svMrtuWzLYv1"
   },
   "source": [
    "What do you expect the outcome of multiplying a 1D array with a 2D array will be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Inhbiu5LH5p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list * np_1d_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceS-_xOQGlfc"
   },
   "source": [
    "### Linear Algebra in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqIh_GjKLhha"
   },
   "source": [
    "Basic linear algebraic operations can also be performed in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I93WQ-QOMnM6"
   },
   "source": [
    "Vector-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXlve9VqLg1b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list @ np_1d_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJh6yQEuMi5p"
   },
   "source": [
    "This also works for matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8SPeY9SMeyd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,0],[0,1]])\n",
    "b = np.array([[4,1],[2,2]])\n",
    "\n",
    "a@b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbaCnwTFLuO1"
   },
   "source": [
    "**EXERCISE**\n",
    "\n",
    "Why does the following code fail?\n",
    "\n",
    "`np_1d_list @ np_2d_list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvYzdEUmL9bV"
   },
   "source": [
    "#### Shapes\n",
    "\n",
    "Numpy arrays have some very useful attributes - particularly size, shape and dtpye\n",
    "\n",
    "1. Size tracks the number of scalar values contained within then array (and any sub-arrays)\n",
    "2. Shape contains the size of each dimension of the array - e.g. shape=(3,4) corresponds to a 3x4 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urauo-4iMK4q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFLw_2AEaBvT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hHgY-k5MTht",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSgGb-8CMuXQ"
   },
   "source": [
    "This becomes even more important when working with tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxlGBrKbMtnk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_tensor_a = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
    "np_tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYoJ61m2M3zX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_tensor_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FtwMvRtOJoS"
   },
   "source": [
    "It is possible to transpose (rotate by 90 degrees) an array with `.T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DN_RQSRdOPur",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_2d_list.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WA6icMvFORvD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_1d_list.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YelgVpXOT7c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_tensor_a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nc8FLDBM7SD"
   },
   "source": [
    "**EXERCISE**\n",
    "\n",
    "What are the requirements (in terms of shape) for two matrices to be multiplicable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMBLRQZvNG1a"
   },
   "source": [
    "#### Re-shaping\n",
    "\n",
    "Given a NumPy array, it is possible to change its shape - provided that the total number of elements matches between the original and new shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fy1SX_xANUoY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_list = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7JkCciFNbF5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_list.reshape( (2,6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUz-m80NNfI2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_list.reshape( (2,3,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJkhiJnbNjg9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_list.reshape( (12,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovx6RUcZNlku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "square_mat = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "square_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3leeLJJpN2c6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "square_mat.reshape( (12,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R24ExK5nNzKR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "square_mat.reshape( (1,12) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fLIDzLTOCC2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "square_mat.reshape( (1,6,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAC04-1iGXM9"
   },
   "source": [
    "## Pandas (https://pandas.pydata.org/)\n",
    "\n",
    "Pandas is a powerful data analysis and manipulation package built on top of NumPy, that operates on tabular (relational) data. This is an extrememly powerful tool, especially for dealing with large and unprocessed datasets. It supports SQL-style queries, and is integatred with PySpark for large-scale processing over distributed databases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHijGN5MOiIv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USdsMCtUP03e"
   },
   "source": [
    "The basic data structures of Pandas are the Series and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvMHd2aiPl-I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array([2,3,62,1,2])\n",
    "series1 = pd.Series(data, name=\"Example Series 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EylmK-I1QPQV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2 = np.log(data)\n",
    "series2 = pd.Series(data2, name=\"Example Series 2\")\n",
    "series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npm2f9uMQVVh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Series 1\": series1, \"Series 2\": series2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L76J9gl0Qjcn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQXCqj82Ql4L"
   },
   "source": [
    "Pandas supports many useful operations over DataFrames\n",
    "\n",
    "1. Indexing over rows and columns\n",
    "2. Simple sumary statistics can be calculated over the columns\n",
    "3. Transformations can be applied to differnt columns\n",
    "4. SQL-like queries over the whole DataFrame, including grouping\n",
    "5. SQL-like merge and intersection operations between DataFrames\n",
    "6. And more ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoXlWaGHRKqQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[0:2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPDGvzWJRN8n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Series 1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVddg3K3RUU5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Series 1'].apply(lambda x: \"High\" if x>6 else \"Low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mn_1Q2H-RcxL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df[\"Series 1\"]>5 & (df[\"Series 2\"]>0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YllCgXY2Ro0U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Series 1\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtpVp9TFRqcy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txjkZmAKRxlx"
   },
   "source": [
    "### Reading from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CB_XnSFkRwbA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/datasciencedojo/datasets/raw/refs/heads/master/titanic.csv\n",
    "!wget https://github.com/andrew-nash/CS6421-labs-2026/raw/refs/heads/main/titanic_test.csv\n",
    "!wget https://github.com/andrew-nash/CS6421-labs-2026/raw/refs/heads/main/titanic_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1xZKZcIR2GL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tianic_df = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxTicHh6R4lu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tianic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czlq99MBZZtQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns = [\"Pclass\",\"Fare\"]\n",
    "tianic_df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCNRaD-PSBW_"
   },
   "outputs": [],
   "source": [
    "######## EXERCISE\n",
    "# Find the average fare for first class passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZbyxaDYSQvN"
   },
   "outputs": [],
   "source": [
    "######## EXERCISE\n",
    "# Get a NumPy array containing the ticket class of passsengers under 18 who did not survive the sinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3rJzQVITDTn"
   },
   "outputs": [],
   "source": [
    "######## ADVANCED EXERCISE\n",
    "# find the number of each class in this array\n",
    "# hint:  https://numpy.org/doc/stable/reference/routines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax\n",
    "\n",
    "Ref. https://docs.jax.dev/en/latest/notebooks/thinking_in_jax.html\n",
    "\n",
    "At the most superficial level, Jax can be considered a hardware-accelerated re-implementation of NumPy (along with some components of Scipy). Amongst other things, it features JIT compilation, and auto-differentiation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can be created similarly to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = [1,2,3,5]\n",
    "\n",
    "jnp_array = jnp.array(l)\n",
    "jnp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jnp.zeros((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_jnp = jnp.linspace(0, 10, 1000)\n",
    "print(x_jnp[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations can also be performed similarly, as well as operations between arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jnp.exp(jnp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "2 * jnp.sin(x_jnp) * jnp.cos(x_jnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jnp_array@jnp_array.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By defauly, Jax compiles and executes each command individually in sequence. For better performance, Jax allows us to combine operations into functions which can then be optimized and JIT compiled together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jax import jit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm(X):\n",
    "    X = X - X.mean(0)\n",
    "    return X / X.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiled_norm = jit(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(1701)\n",
    "X = jnp.array(np.random.rand(10, 2))\n",
    "np.allclose(norm(X), compiled_norm(X), atol=1E-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Key Caveats/Gotchas when using Jax, compared to NumPy:\n",
    "\n",
    "1. JIT compiled Jax functions must be \"functionally pure\", i.e. the output is dependant only on the function arguments, with no side-effects. Such functions cannot read or update globabl variables, or otherwise interact with any object or variable outside the scope of the function. **This includes performing `print()` statements**. Further, JIT functions require the shapes of all arrays to be static, and known at compile time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = 0.\n",
    "def impure_uses_globals(x):\n",
    "    return x + g\n",
    "\n",
    "# JAX captures the value of the global during the first run\n",
    "print (\"First call: \", jit(impure_uses_globals)(4.))\n",
    "g = 10.  # Update the global\n",
    "\n",
    "# Subsequent runs may silently use the cached value of the globals\n",
    "print (\"Second call: \", jit(impure_uses_globals)(5.))\n",
    "\n",
    "# JAX re-runs the Python function when the type or shape of the argument changes\n",
    "# This will end up reading the latest value of the global\n",
    "print (\"Third call, different type: \", jit(impure_uses_globals)(jnp.array([4.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_negatives(x):\n",
    "    return x[x < 0]\n",
    "\n",
    "x = jnp.array(np.random.randn(10))\n",
    "get_negatives(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = jnp.array(np.random.randn(10))\n",
    "get_negatives(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how, without knowing the specific values of `x`, it is impossible to determine the output hsape of this function, and therefore it cannot be JIT compiled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Jax arrays (unlike NumPy) are immutable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jax_array = jnp.zeros((3,3), dtype=jnp.float32)\n",
    "\n",
    "# In place update of JAX's array will yield an error!\n",
    "jax_array[1, :] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, if in place updates are required, Jax provides a functional approach:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_array = jax_array.at[1, :].set(1.0)\n",
    "print(\"updated array:\\n\", updated_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when using `+=` and similar contractions in Jax. Bear in mind that unlike NumPy, these are not in-place updates, but invove re-creating the entire array. It is better practice to use Jax's functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_array += 1.0\n",
    "print(\"updated array:\\n\", updated_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "Ref. https://docs.pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Ref. https://docs.pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label\n",
    "\n",
    "In PyTorch, the the main underlying structure in which basic data is stored is the Tensor. These are very similar to NumPy arrays -- to the point that a PyTorch Tensor and NumPy array can in some instances share the same location in memory. The key advantage of the PyTorch Tensors is that, similarly to Jax arrays, they can run on GPU (and other accelerator hardware)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can be created from data, random or constant values, or from NumPy arrays. In practice, I would recommend either creating Tensors from constant values, or from a NumPy array in all other situations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to Jax and Numpy, PyTorch supports a number of operations on Tensors. If you wish to perform these operations on a GPU (to include running and training a DL model) however, you must insturct PyTorch to store the Tensor on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_np = x_np.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see this in practice shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have pre-processed our data, and are ready to train some deep learning models, we need to load them into a format that is compatible with PyTorch's own operations.\n",
    "\n",
    "PyTorch is designed to train over user-defined `Dataset` objects, which implement a `__getitem__` function. From this function, we rturn one row (X,Y) of data.\n",
    "\n",
    "In this example, we will use Pandas and NumPy to load and pre-process the Titanic  dataset. We are going to consider as factors: Age, Sex, Ticket Class, And Embarkation Location\n",
    "\n",
    "\n",
    "Ref. https://medium.com/@akashgajjar8/titanic-survival-prediction-using-pytorch-a5b9fb4eca53, https://medium.com/@aisgandy/predicting-titanic-survival-with-deep-learning-a-stripped-down-approach-7aa8cdb37c0e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TitanicDataset (torch.utils.data.Dataset):\n",
    "    # the Train argument defines whether the dataset is being queried for train or test data\n",
    "    # In practice, you would likely be handling separate datasets for each\n",
    "    def __init__(self, file_name, Train=True):\n",
    "        self.dataframe = pd.read_csv(file_name)\n",
    "        #print(self.dataframe.head())\n",
    "        self.dataframe = self.dataframe.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "        self.dataframe = self.dataframe.drop(['SibSp', 'Parch'], axis=1)    \n",
    "\n",
    "        self.dataframe = self.dataframe.dropna(subset=['Age', 'Embarked', 'Sex', 'Pclass', 'Fare'])\n",
    "        \n",
    "        # Instead of using strings (\"Male\" and \"Female\"), we need to convert these to numerical values -- in this \n",
    "        # case 1 for male, 0 for female\n",
    "        self.dataframe['Male'] = np.where(self.dataframe['Sex'] == 'male', 1, 0)\n",
    "\n",
    "        # Manual one-hot encoding for Embarked, using np.where\n",
    "\n",
    "        # Embarked locations are: C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "        # Embarked_C = 1, if embarked from Cherbourg, 0 otherwise\n",
    "        # Embarked_S = 1, if embarked from Southampton, 0 otherwise\n",
    "        # Embarked_ = 0 and Embarked_S = 0, if embarked from Queenstown (now Cobh ...)\n",
    "        self.dataframe['Embarked_C'] = np.where(self.dataframe['Embarked'] == 'C', 1, 0)\n",
    "        self.dataframe['Embarked_S'] = np.where(self.dataframe['Embarked'] == 'S', 1, 0)\n",
    "\n",
    "        # Remove original Sex and Embarked columns\n",
    "        self.dataframe = self.dataframe.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "        # We can achieve the same one-hot encoding for Pclass using Pandas get_dummies function, instead of the \n",
    "        # manual np.where approach above\n",
    "        self.dataframe[['Pclass_1', 'Pclass_2']] = pd.get_dummies(self.dataframe['Pclass'], prefix='Pclass').iloc[:, :2].astype(int)\n",
    "        self.dataframe = self.dataframe.drop(['Pclass'], axis=1)\n",
    "\n",
    "\n",
    "        # Nomralisation\n",
    "        self.dataframe['Age_N'] = self.dataframe['Age']/self.dataframe['Age'].max()\n",
    "\n",
    "        # An example of a log transform\n",
    "        self.dataframe['log_Fare'] = np.log10(self.dataframe['Fare'] + 1)\n",
    "        self.dataframe = self.dataframe.drop(['Age', 'Fare'], axis=1)\n",
    "        \n",
    "        self.dataframe.reset_index()\n",
    "        self.Train = Train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.Train :\n",
    "            survived = self.dataframe['Survived']\n",
    "            survived = np.array(survived)[idx]\n",
    "        features = pd.DataFrame(columns=('Male',  'Embarked_C', 'Embarked_S', 'Pclass_1', 'Pclass_2', 'Age_N', 'log_Fare'))\n",
    "        \n",
    "        # Bear in mind that the test dataset will not have a Survived column\n",
    "        if self.Train:\n",
    "            features = self.dataframe.iloc[idx,1:]\n",
    "        else:\n",
    "            features = self.dataframe.iloc[idx,:]\n",
    "            \n",
    "        features = features.to_numpy()\n",
    "        if self.Train:\n",
    "            sample = ( features, survived)\n",
    "        else:\n",
    "            sample = features\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = TitanicDataset('titanic_train.csv')\n",
    "testing_data = TitanicDataset('titanic_test.csv', Train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleFeedforward(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleFeedforward, self).__init__()\n",
    "        \n",
    "        # Defines our modules/layers, in this case all\n",
    "        # linear layers of the form y = Ax + b\n",
    "        \n",
    "        # The number of inputs must match our features\n",
    "        self.dl1 = nn.Linear(7, 4)\n",
    "        self.dl2 = nn.Linear(4, 5)\n",
    "        self.dl3 = nn.Linear(5, 1)\n",
    "        \n",
    "        # finish with a sigmoid layer, to generate an \n",
    "        # output between 0 and 1        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Appply forward popogation on these layers\n",
    "        x = F.relu(self.dl1(x))\n",
    "        x = F.relu(self.dl2(x))\n",
    "        x = self.sigmoid(self.dl3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have been given acess to a machine with high power GOU capabilities, we might as well make sure that our model is executing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.accelerator.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.accelerator.current_accelerator().type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above outputs are True and 'cuda', then PyTorch is configur correctly to work wih the GPU. When cree an instace of out model, we must make sure to specifiythat it should execute on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SimpleFeedforward().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply execute the feedforward phase by passing the model data.\n",
    "\n",
    "We first need to convert the data into a PyTorch tensor (of type float, which in Pytorch corresponds to a 32-bit float), and specify that it should be exectued on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = torch.from_numpy(training_data[0][0]).float().to('cuda')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Backpropogation and Gradient Updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameters\n",
    "\n",
    "Before we can perform Backprop, we must define out hyper-parameters, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we must wrap our Dataset in a PyTorch DataLoader. Before we do so, it can be wrothwhile to split out train dataset into train and validation sets, which allow us to better assess model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_train_dataset, val_dataset = torch.utils.data.random_split(training_data, [0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wrap these with DataLoaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(sub_train_dataset, batch_size=64)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define out model training loop which\n",
    "\n",
    "1. Performs forward propogation\n",
    "2. Performs backward propogration to compute the weight and bias gradients\n",
    "3. Applies weight and bias updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.float().to('cuda')\n",
    "        \n",
    "        # add a dummy dimension to the outputs to match the model \n",
    "        # output\n",
    "        y = torch.reshape(y.float().to('cuda'), (-1, 1))\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.float().to('cuda')\n",
    "            y = torch.reshape(y.float().to('cuda'), (-1, 1))\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.round(pred)==y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all that remains to train the model is to invoke these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    val_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving the Models\n",
    "\n",
    "The performance of this model is obviously very poor. We can increase the complexity of the model, and obsere the difference in performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ComplexFeedforward(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexFeedforward, self).__init__()\n",
    "        \n",
    "        # Defines our layers, all linear layers\n",
    "        # of the form y = Ax + b\n",
    "        \n",
    "        # The number of inputs must match our features\n",
    "        self.dl1 = nn.Linear(7, 32)\n",
    "        self.dl2 = nn.Linear(32, 64)\n",
    "        self.dl3 = nn.Linear(64, 128)\n",
    "        self.dl4 = nn.Linear(128, 64)\n",
    "        self.dl5 = nn.Linear(64, 1)\n",
    "        \n",
    "        # finish with a sigmoid layer, to generate a \n",
    "        # output between 0 and 1        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Appply forward popogation on these layers\n",
    "        x = F.relu(self.dl1(x))\n",
    "        x = F.relu(self.dl2(x))\n",
    "        x = F.relu(self.dl3(x))\n",
    "        x = F.relu(self.dl4(x))\n",
    "        x = self.sigmoid(self.dl5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ComplexFeedforward().to('cuda')\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    val_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyter-student",
   "language": "python",
   "name": "jupyter-eg-kernel-slurm-py-conda-1ja8rhof9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
